{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-25T09:24:45.379862Z",
     "start_time": "2018-06-25T09:24:45.371304Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from importlib import reload\n",
    "\n",
    "import simulate\n",
    "from simulate import simulate_data, bayes_boundary, parabola, circle, boundary_1\n",
    "import plotting\n",
    "from plotting import plot_two_variables, plot_roc_curve, plot_clf_decision_boundary, plot_strategy_curve, plot_classifier_profit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulation\n",
    "\n",
    "For the purpose of teaching, we will simulate a dataset where we know how the targets are assigned.<br>\n",
    "\n",
    "The dataset will contain 3000 rows and two columns, so that we can visually understand what is going on. <br>\n",
    "\n",
    "<b> Note: this is a very ideal simple scenario for visual understanding. This will not work in real life\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-25T09:24:45.391216Z",
     "start_time": "2018-06-25T09:24:45.383297Z"
    }
   },
   "outputs": [],
   "source": [
    "N_population = 3000\n",
    "data = simulate_data(population_size=N_population, N_cont_variables=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the Bayesian Classifier boundary functions\n",
    "\n",
    "Here we define the targets on our simulated dataset with a non linear separation. <br>\n",
    "We will plot the points later for visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-25T09:24:45.479726Z",
     "start_time": "2018-06-25T09:24:45.393173Z"
    }
   },
   "outputs": [],
   "source": [
    "probs,targets,coordinates = bayes_boundary(\n",
    "    boundary_func=parabola,\n",
    "    print_median=False, \n",
    "    x = data['col_0'], y = data['col_1'],\n",
    "    max_accuracy=1)\n",
    "\n",
    "# assign it to the dataset\n",
    "data['y']=targets\n",
    "\n",
    "#show the first five values\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the Bayesian Classifier boundaries\n",
    "\n",
    "Let's plot the points for visualising the data we are dealing with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-25T09:24:45.850449Z",
     "start_time": "2018-06-25T09:24:45.484518Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15, 10))\n",
    "plot_two_variables(df=data, fig=fig, ax=ax,plot_separation_boundary=True, boundary_func=parabola)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine learning\n",
    "\n",
    "Let's try to build some models to run the classifications.<br>\n",
    "\n",
    "We will try the following models:\n",
    "- **Logistic regression**: it is a linear model, which is the most common in building score cards. We will try to illustrate the limitations of this model\n",
    "- **Random forest**: a tree-based ensemble model, which has more flexibility in splitting classes, but is prone to overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train test split\n",
    "We need to separate our sample in a training sample (where we build the model) and a test sample (where we can evaluate the model performance).<br>\n",
    "The `train_test_split` function of scikit-learn is helpful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-25T09:24:45.857127Z",
     "start_time": "2018-06-25T09:24:45.852037Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-25T09:24:45.865958Z",
     "start_time": "2018-06-25T09:24:45.859599Z"
    }
   },
   "outputs": [],
   "source": [
    "# it is always a good idea to explicitly specify which columns represent the data to train on, and which columns are\n",
    "# the targets\n",
    "X = data[['col_0','col_1']]\n",
    "y = data['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-25T09:24:45.876865Z",
     "start_time": "2018-06-25T09:24:45.867948Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.375, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-25T09:24:45.885492Z",
     "start_time": "2018-06-25T09:24:45.878554Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear model - logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-25T09:24:46.838575Z",
     "start_time": "2018-06-25T09:24:45.887157Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-25T09:24:46.856915Z",
     "start_time": "2018-06-25T09:24:46.843710Z"
    }
   },
   "outputs": [],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-25T09:24:47.077877Z",
     "start_time": "2018-06-25T09:24:46.861708Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 10))\n",
    "plot_roc_curve(lr,X_train,y_train, ax=ax, color='darkgreen',label = 'Train AUC')\n",
    "plot_roc_curve(lr,X_test,y_test, ax=ax, color='salmon', label = 'Test AUC ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The AUC seems quite good. But let's have a look at the decision boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-25T09:24:47.086558Z",
     "start_time": "2018-06-25T09:24:47.082466Z"
    }
   },
   "outputs": [],
   "source": [
    "reload(plotting)\n",
    "from plotting import plot_clf_decision_boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-25T09:24:48.089758Z",
     "start_time": "2018-06-25T09:24:47.090924Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_clf_decision_boundary(df=data,clf =lr, plot_classifier_boundary = True, plot_classifier_prob_map=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a non linear model - Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-25T09:24:48.574321Z",
     "start_time": "2018-06-25T09:24:48.094346Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-25T09:24:48.582808Z",
     "start_time": "2018-06-25T09:24:48.579391Z"
    }
   },
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-25T09:24:48.612850Z",
     "start_time": "2018-06-25T09:24:48.586923Z"
    }
   },
   "outputs": [],
   "source": [
    "rf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-25T09:24:48.830118Z",
     "start_time": "2018-06-25T09:24:48.617502Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 10))\n",
    "plot_roc_curve(rf,X_train,y_train, ax=ax, color='darkgreen',label = 'Train AUC')\n",
    "plot_roc_curve(rf,X_test,y_test, ax=ax, color='purple', label = 'Test AUC ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-25T09:24:50.637344Z",
     "start_time": "2018-06-25T09:24:48.834688Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15, 10))\n",
    "plot_clf_decision_boundary(df=X_train, target = y_train,ax=ax, clf =rf, \n",
    "                           plot_classifier_boundary = True,plot_classifier_prob_map=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Random Forest separates the classes (almost) perfectly. But, this is too ideal to be true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A more realistic scenario\n",
    "In this simulated example, we have a clear (tough non-linear) separation between the two classes.<br>\n",
    "Let's generate a more realistic scenario, where there is no perfect separation possible, i.e the irreducible error is not zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-25T09:24:50.663792Z",
     "start_time": "2018-06-25T09:24:50.641908Z"
    }
   },
   "outputs": [],
   "source": [
    "probs,targets,coordinates = bayes_boundary(\n",
    "    boundary_func=parabola,\n",
    "    print_median=False, \n",
    "    x = data['col_0'], y = data['col_1'],\n",
    "    max_accuracy=0.92) # in this case, 8% of my observations will randomly swap classes\n",
    "\n",
    "# assign it to the dataset\n",
    "data['y']=targets\n",
    "\n",
    "#show the first five values\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-25T09:24:50.672275Z",
     "start_time": "2018-06-25T09:24:50.668369Z"
    }
   },
   "outputs": [],
   "source": [
    "reload(plotting)\n",
    "from plotting import plot_two_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-25T09:24:50.972232Z",
     "start_time": "2018-06-25T09:24:50.677009Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15, 10))\n",
    "plot_two_variables(df=data, fig=fig, ax=ax,plot_bayes_colourmap = False, plot_separation_boundary=True,boundary_func=parabola)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### As you can see, now some red points are deep in the blue area and viceversa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's redo now the train test split, as we have a new sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-25T09:24:50.985917Z",
     "start_time": "2018-06-25T09:24:50.976773Z"
    }
   },
   "outputs": [],
   "source": [
    "# it is always a good idea to explicitly specify which columns represent the data to train on, and which columns are\n",
    "# the targets\n",
    "X = data[['col_0','col_1']]\n",
    "y = data['y']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.375, random_state=42)\n",
    "\n",
    "X_train.shape,X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train again the logisitc regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-25T09:24:50.999974Z",
     "start_time": "2018-06-25T09:24:50.990368Z"
    }
   },
   "outputs": [],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-25T09:24:51.215320Z",
     "start_time": "2018-06-25T09:24:51.004441Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 10))\n",
    "plot_roc_curve(lr,X_train,y_train, ax=ax, color='darkgreen',label = 'Train AUC')\n",
    "plot_roc_curve(lr,X_test,y_test, ax=ax, color='purple', label = 'Test AUC ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-25T09:24:51.619882Z",
     "start_time": "2018-06-25T09:24:51.219910Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_clf_decision_boundary(df=data,clf =lr, plot_classifier_boundary = True,plot_classifier_decisions=False,\n",
    "                           plot_classifier_prob_map=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### And now, the Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-25T09:24:51.656713Z",
     "start_time": "2018-06-25T09:24:51.624431Z"
    }
   },
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-25T09:24:51.877076Z",
     "start_time": "2018-06-25T09:24:51.661420Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 10))\n",
    "plot_roc_curve(rf,X_train,y_train, ax=ax, color='darkgreen',label = 'Train AUC')\n",
    "plot_roc_curve(rf,X_test,y_test, ax=ax, color='purple', label = 'Test AUC ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What happend? \n",
    "What can you tell from the AUC score on the training set and the AUC score on the test set?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's see the decision boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-25T09:24:56.928024Z",
     "start_time": "2018-06-25T09:24:51.881642Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2,1,figsize=(15, 20))\n",
    "ax[0].set_title('Training set', size='xx-large')\n",
    "plot_clf_decision_boundary(df=X_train, target = y_train,fig = fig,ax = ax[0], clf =rf, \n",
    "                           plot_classifier_boundary = False,plot_classifier_prob_map=True)\n",
    "ax[1].set_title('Test set', size='xx-large')\n",
    "plot_clf_decision_boundary(df=X_test, target = y_test,fig = fig, ax = ax[1], clf =rf, \n",
    "                           plot_classifier_boundary = False,plot_classifier_prob_map=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's be a bit more concrete. How much money do we actually make? \n",
    "### At the end of the day we are a bank, and we would like to estimate the profit of the portfolio\n",
    "\n",
    "For this esimation, we need to think of some reasonable hypotheses. <br>\n",
    "\n",
    "For the sake of simplicity, let's assume that each client borrows on average 10000 euros for a period of 5 years.<br>\n",
    "\n",
    "<img src=\"images/Loan_on_18june.png\" alt=\"Drawing\" style=\"width: 600px;\"/>\n",
    "<br>\n",
    "According to the ING offer on June 18th, at an interest rate of 7,40% for the period, the client would repay 11927 euros.<br>\n",
    "This means that the average profit per good cliend is 1927 euros.<br>\n",
    "<br>\n",
    "If the client defaults, we can assume that we lose 10000 euros, the average amount we disburse.<br>\n",
    "<br>\n",
    "Let's plot the profit of the current portfolio under the above mentioned assumptions.<br>\n",
    "<br>\n",
    "For this we set `cost_of_bads=10000` and `profit_of_goods=1927`\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-25T09:24:57.218416Z",
     "start_time": "2018-06-25T09:24:56.929953Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15, 10))\n",
    "\n",
    "plot_classifier_profit(lr,X_test,y_test,ax=ax, color ='red',label = 'Logistic test',\n",
    "                       cost_of_bads=10000,profit_of_goods=1927)\n",
    "plot_classifier_profit(rf,X_test,y_test,ax=ax ,color ='blue',label = 'RF test',\n",
    "                       cost_of_bads=10000,profit_of_goods=1927)\n",
    "\n",
    "#uncommetd this two lines to zoom in the ared of interest\n",
    "#ax.set_xlim(0,0.8) # x axis range\n",
    "ax.set_ylim(-1e6,5e5) # y axis range\n",
    "\n",
    "#ax.set_ylim(-1,2) # y axis range\n",
    "ax.legend(loc='upper right')\n",
    "#ax.plot([0, 1], [0, 0], color='navy', lw=2, linestyle='--')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Strategy curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-25T09:24:57.634352Z",
     "start_time": "2018-06-25T09:24:57.223110Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15, 10))\n",
    "plot_strategy_curve(lr,X_train, y_train,ax=ax, color ='red',label = 'Logistic')\n",
    "\n",
    "plot_strategy_curve(rf,X_train, y_train,ax=ax,  color ='blue',label = 'RF test')\n",
    "ax.legend(loc='upper left')\n",
    "\n",
    "ax.set_xlim(0,1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXERCISE\n",
    "\n",
    "- check the hyperparameters of the RandomForest (try `help(RandomForestClassifier)`)\n",
    "- try modifing the hypterparameteres until you reach a better generalization and you reduce the overfitting\n",
    "\n",
    "**tip** consider the `n_estimators` and the `max_depth`\n",
    "\n",
    "\n",
    "**Note** the training time increases with n_estimators:\n",
    "* with 10 trees takes cca 3-4 seconds\n",
    "* with 100 trees takes cca 20-30 seconds\n",
    "* with 1000 trees takes cca 8-10 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-25T09:25:05.586960Z",
     "start_time": "2018-06-25T09:24:57.639131Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "rf_exercise = RandomForestClassifier(\n",
    "n_estimators=<enter_value>\n",
    "max_depth=<enter_value>\n",
    ")\n",
    "rf_exercise.fit(X_train,y_train)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 10))\n",
    "plot_roc_curve(rf_exercise,X_train,y_train, ax=ax, color='darkgreen',label = 'Train AUC')\n",
    "plot_roc_curve(rf_exercise,X_test,y_test, ax=ax, color='purple', label = 'Test AUC ')\n",
    "\n",
    "fig, ax = plt.subplots(2,1,figsize=(15, 20))\n",
    "ax[0].set_title('Training set', size='xx-large')\n",
    "plot_clf_decision_boundary(df=X_train, target = y_train,fig = fig,ax = ax[0], clf =rf_exercise, \n",
    "                           plot_classifier_boundary = True,plot_classifier_prob_map=True)\n",
    "ax[1].set_title('Test set', size='xx-large')\n",
    "plot_clf_decision_boundary(df=X_test, target = y_test,fig = fig, ax = ax[1], clf =rf_exercise, \n",
    "                           plot_classifier_boundary = True,plot_classifier_prob_map=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's get an idea of how hyperparemeters affect the model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-25T09:25:57.894522Z",
     "start_time": "2018-06-25T09:25:57.890947Z"
    }
   },
   "outputs": [],
   "source": [
    "from plotting import plot_score_vs_hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-25T09:26:16.120981Z",
     "start_time": "2018-06-25T09:25:58.473730Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "rf_test = RandomForestClassifier(random_state=42,n_estimators=10, max_depth=3)\n",
    "param_grid={'n_estimators': range(1, 60, 1)}\n",
    "\n",
    "plot_score_vs_hyperparameter(rf_test,X_train,y_train, scoring_metric = 'roc_auc',param_grid=param_grid)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-25T09:26:20.893711Z",
     "start_time": "2018-06-25T09:26:16.125746Z"
    }
   },
   "outputs": [],
   "source": [
    "rf_test = RandomForestClassifier(random_state=42,n_estimators=10)\n",
    "param_grid={'min_samples_split': range(2, 800, 20)}\n",
    "\n",
    "plot_score_vs_hyperparameter(rf_test,X_train,y_train, scoring_metric = 'roc_auc',param_grid=param_grid)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-25T09:26:27.745106Z",
     "start_time": "2018-06-25T09:26:20.898441Z"
    }
   },
   "outputs": [],
   "source": [
    "param_grid={'max_depth': list(range(1, 20, 1))}\n",
    "#param_grid={'min_samples_split': range(2, 800, 20)}\n",
    "plot_score_vs_hyperparameter(RandomForestClassifier(n_estimators=40,max_depth=8,min_samples_split=500),\n",
    "                             X_train,y_train, \n",
    "                             scoring_metric = 'roc_auc',\n",
    "                             param_grid=param_grid)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-25T09:26:27.753447Z",
     "start_time": "2018-06-25T09:26:27.749753Z"
    }
   },
   "outputs": [],
   "source": [
    "final_rf = RandomForestClassifier(n_estimators=40,max_depth=8,min_samples_split=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-25T09:26:27.826721Z",
     "start_time": "2018-06-25T09:26:27.758255Z"
    }
   },
   "outputs": [],
   "source": [
    "final_rf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-25T09:26:52.023914Z",
     "start_time": "2018-06-25T09:26:27.831397Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2,1,figsize=(15, 20))\n",
    "ax[0].set_title('Training set', size='xx-large')\n",
    "plot_clf_decision_boundary(df=X_train, target = y_train,fig = fig,ax = ax[0], clf =final_rf, \n",
    "                           plot_classifier_boundary = True,plot_classifier_prob_map=True)\n",
    "ax[1].set_title('Test set', size='xx-large')\n",
    "plot_clf_decision_boundary(df=X_test, target = y_test,fig = fig, ax = ax[1], clf =final_rf, \n",
    "                           plot_classifier_boundary = True,plot_classifier_prob_map=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:iitp]",
   "language": "python",
   "name": "conda-env-iitp-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
