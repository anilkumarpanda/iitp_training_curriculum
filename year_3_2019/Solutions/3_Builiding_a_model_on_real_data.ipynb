{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling \n",
    "\n",
    "* In this notebook we will build a machine learning model using the data we processed in the previous session.<br>\n",
    "* Scikit-learn is a very popular library for Machine Learning in Python. We will explore its API and use it\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T19:15:44.972373Z",
     "start_time": "2019-06-25T19:15:44.967439Z"
    }
   },
   "outputs": [],
   "source": [
    "#import packages\n",
    "#for dealing with data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# for changing working directory\n",
    "import os\n",
    "#for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "#plt.style.use('ggplot')\n",
    "pd.set_option('display.max_rows', 50)\n",
    "pd.set_option('display.max_columns', 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T19:15:45.306530Z",
     "start_time": "2019-06-25T19:15:45.303702Z"
    }
   },
   "outputs": [],
   "source": [
    "# scikit learn packages\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, roc_auc_score, roc_curve, accuracy_score, \\\n",
    "                            precision_score, recall_score, make_scorer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T19:15:46.401606Z",
     "start_time": "2019-06-25T19:15:46.275420Z"
    }
   },
   "outputs": [],
   "source": [
    "! ls data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T19:15:47.077087Z",
     "start_time": "2019-06-25T19:15:46.925023Z"
    }
   },
   "outputs": [],
   "source": [
    "data=pd.read_csv('data/processed_data.csv',index_col='Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T19:15:47.667353Z",
     "start_time": "2019-06-25T19:15:47.641020Z"
    }
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's check again the columns we have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T19:15:48.723602Z",
     "start_time": "2019-06-25T19:15:48.719316Z"
    }
   },
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some questions we should ask ourselves before we start modelling\n",
    "### What is the goal of our model?\n",
    "* We want to predict the target y (default yes/no) based on a set of features/risk drivers X\n",
    "* We already did some preprocessing of the data in the previous notebook, however, we not all the variables that we have make sense\n",
    "* For instance, `ID` cannot have any predictive power, so we should drop it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T19:15:49.460261Z",
     "start_time": "2019-06-25T19:15:49.451594Z"
    }
   },
   "outputs": [],
   "source": [
    "data.drop('ID',inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T19:15:50.537800Z",
     "start_time": "2019-06-25T19:15:50.533213Z"
    }
   },
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do we have enough defaults in our portfolio?\n",
    "Let's check it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T19:15:51.845896Z",
     "start_time": "2019-06-25T19:15:51.839476Z"
    }
   },
   "outputs": [],
   "source": [
    "data['default.payment.next.month'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 6636 defaults (22%), and 23364 (78%) of no defaults.<br>\n",
    "The targets are not balances, but this is not a problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How much data do we use for training our model, and how much for validating it?\n",
    "The general rule of thumbs for splitting the data is 70%/30% or 80%/20%.<br>\n",
    "What matters is that we keep having enough targets in our sample, and that the distributions between our training and test set do not change. <br>\n",
    "We can use the train_test_split() function from sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T19:15:53.326850Z",
     "start_time": "2019-06-25T19:15:53.323222Z"
    }
   },
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T19:15:53.914403Z",
     "start_time": "2019-06-25T19:15:53.892155Z"
    }
   },
   "outputs": [],
   "source": [
    "# let' split it in 75% training and 25% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data.drop(['default.payment.next.month','MARRIAGE_OTHER','SEX_MALE','EDUCATION_UNKNOWN'], axis=1),\n",
    "    data['default.payment.next.month'],test_size=0.25)\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(data[['PAY_1']],\n",
    "#                                                     data['default.payment.next.month'],test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T19:15:54.233698Z",
     "start_time": "2019-06-25T19:15:54.230213Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T19:15:54.637888Z",
     "start_time": "2019-06-25T19:15:54.634357Z"
    }
   },
   "outputs": [],
   "source": [
    "X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T19:15:55.258087Z",
     "start_time": "2019-06-25T19:15:55.254205Z"
    }
   },
   "outputs": [],
   "source": [
    "# Sanity check \n",
    "X_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We should check how the targets are distributed in the train and test samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise:\n",
    "Check the target distribution in the two samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T19:16:30.246112Z",
     "start_time": "2019-06-25T19:16:30.239440Z"
    }
   },
   "outputs": [],
   "source": [
    "print(y_train.value_counts())\n",
    "print(y_test.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As one should expect:\n",
    "* it follows the train test split (i.e. cca 75% of the bads are in the training set and 25% of the bads are in the test set)\n",
    "* the distribution within the sample is cca 22% of bads, as in the complete sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What about the features?\n",
    "We do not want that the features are very different in the train and test set, because our validation might be wrong if this is the case.<br>\n",
    "There are different approaches to estimate the stability of the features distribution, but for the sake of simplicity we are happy with checking if the mean of the distribution is similar or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T19:16:36.527922Z",
     "start_time": "2019-06-25T19:16:36.480870Z"
    }
   },
   "outputs": [],
   "source": [
    "for col in X_train.columns:\n",
    "    print('\\ncolumn name:',col)\n",
    "    print('training mean %.2f'%(X_train[col].mean()),' - test mean %.2f'%(X_test[col].mean()),\n",
    "          ' - train/test mean: %.2f'%(X_train[col].mean()/X_test[col].mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The first model\n",
    "Let's start simple and classical, and begin with a Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T19:16:40.042769Z",
     "start_time": "2019-06-25T19:16:40.040371Z"
    }
   },
   "outputs": [],
   "source": [
    "# Defining the model\n",
    "lr = LogisticRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model\n",
    "In the scikit learn API, training and algorithm is done bu the `fit()` function.\n",
    "One can use the `predict()` or `predict_proba()` to predict the outcome or predict the probability for the outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T19:16:41.602561Z",
     "start_time": "2019-06-25T19:16:40.971116Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "lr.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training a logisitc regression is very fast, it took less than a second"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting the outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T19:16:44.664423Z",
     "start_time": "2019-06-25T19:16:44.656600Z"
    }
   },
   "outputs": [],
   "source": [
    "# it returns an array of 0 and 1\n",
    "predictions = lr.predict(X_test)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T19:16:45.083138Z",
     "start_time": "2019-06-25T19:16:45.076910Z"
    }
   },
   "outputs": [],
   "source": [
    "predicted_probs=lr.predict_proba(X_test)\n",
    "predicted_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T19:16:45.634898Z",
     "start_time": "2019-06-25T19:16:45.630845Z"
    }
   },
   "outputs": [],
   "source": [
    "predicted_probs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, predicted_proba returns a matrix of 7500 rows and two columns. Let's read the API documentation to understand why"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T19:16:46.850029Z",
     "start_time": "2019-06-25T19:16:46.846937Z"
    }
   },
   "outputs": [],
   "source": [
    "help(lr.predict_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It says that it returns the probability of the classes.<br>\n",
    "It means that the first array will show the probability of class 0 (no defaults) and the second array shows the probability of class 1 (defaults).<br>\n",
    "We are interested in the probability of defaults, hence the probability of being 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T19:16:48.063835Z",
     "start_time": "2019-06-25T19:16:48.059714Z"
    }
   },
   "outputs": [],
   "source": [
    "predicted_probs[:,1] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How well does my model perform?\n",
    "We need some metric to evaluate the model.<br>\n",
    "`sklearn.metrics` offers a lot of them.<br>\n",
    "Let's see some examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T19:16:48.866140Z",
     "start_time": "2019-06-25T19:16:48.863438Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, accuracy_score, confusion_matrix\n",
    "from sklearn.metrics import classification_report, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T19:16:49.186034Z",
     "start_time": "2019-06-25T19:16:49.182376Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Accuracy: %.3f'%accuracy_score(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T19:16:49.729980Z",
     "start_time": "2019-06-25T19:16:49.727626Z"
    }
   },
   "outputs": [],
   "source": [
    "from plotting import plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T19:16:50.640129Z",
     "start_time": "2019-06-25T19:16:50.472264Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_confusion_matrix(lr,X_train,y_train,threshold=0.5,cmap=plt.cm.Oranges, normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What's wrong here?\n",
    "* The model has a decent precision (78%) but the confusion matrix looks a bit weird, right? What is going on here?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson learned: some metrics might be misleading - we need to check more than just the accuracy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T19:16:52.564062Z",
     "start_time": "2019-06-25T19:16:52.552525Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Precision:',precision_score(y_test,predictions))\n",
    "print('Recall:',recall_score(y_test,predictions))\n",
    "print('AUC score: %.3f'%(roc_auc_score(y_test,predicted_probs[:,1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T19:16:53.150515Z",
     "start_time": "2019-06-25T19:16:53.139424Z"
    }
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### And if I change my model threshold?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T19:16:55.758419Z",
     "start_time": "2019-06-25T19:16:55.580803Z"
    }
   },
   "outputs": [],
   "source": [
    "threshold = 0.1\n",
    "predictions_015 = np.array(list(map(lambda x: 1 if x else 0, lr.predict_proba(X_test)[:,1]>threshold)))\n",
    "print('Accuracy: %.3f'%accuracy_score(y_test,predictions_015))\n",
    "print('Precision:',precision_score(y_test,predictions_015))\n",
    "print('Recall:',recall_score(y_test,predictions_015))\n",
    "print('AUC score: %.3f'%(roc_auc_score(y_test,predicted_probs[:,1])))\n",
    "\n",
    "plot_confusion_matrix(lr,X_train,y_train,threshold=threshold,cmap=plt.cm.Oranges, normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AUC is threshold indipendent!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T19:16:56.650258Z",
     "start_time": "2019-06-25T19:16:56.430579Z"
    }
   },
   "outputs": [],
   "source": [
    "from plotting import plot_precision_recall_curve,plot_roc_curve\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "plot_roc_curve(lr,X_train,y_train, ax, label='train')\n",
    "plot_roc_curve(lr,X_test,y_test, ax, label='test',color = 'green')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's try a non-linear model\n",
    "\n",
    "## Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise: \n",
    "create and train a Random forest classifier. <br>\n",
    "tip: check how we created and trained a Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T19:17:23.859395Z",
     "start_time": "2019-06-25T19:17:23.342797Z"
    }
   },
   "outputs": [],
   "source": [
    "rf_default = RandomForestClassifier()\n",
    "rf_default.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T19:17:26.892192Z",
     "start_time": "2019-06-25T19:17:26.661030Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "plot_roc_curve(rf_default,X_train,y_train, ax, label='train')\n",
    "plot_roc_curve(rf_default,X_test,y_test, ax, label='test',color = 'green')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Another curve we would like to see is the precision vs recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T19:17:30.248929Z",
     "start_time": "2019-06-25T19:17:30.021241Z"
    }
   },
   "outputs": [],
   "source": [
    "from plotting import plot_precision_recall_curve\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "plot_precision_recall_curve(rf_default,X_train,y_train, ax, label='train')\n",
    "plot_precision_recall_curve(rf_default,X_test,y_test, ax, label='test',color = 'green')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise:\n",
    "what can you conclude from the ROC AUC curve and the precision vs recall curve?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** answer ***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Let' try to evaluate our models in terms of impact on the portfolio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXERCISE\n",
    "\n",
    "1. Test different Random Forest hyperparameters.\n",
    "2. What is the effect of each change of the parametrs to model performance & ofer/under-fitting?\n",
    "\n",
    "Note: Things you can try:\n",
    "1. more trees\n",
    "2. set max_depth\n",
    "3. set min_samples_leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T19:18:34.278861Z",
     "start_time": "2019-06-25T19:18:31.765027Z"
    }
   },
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=500, \n",
    "#                             criterion='gini',\n",
    "                            min_samples_leaf=100,\n",
    "                            max_depth=6,\n",
    "                            random_state=24423,\n",
    "                            n_jobs=-1,\n",
    "                           )\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "plot_roc_curve(rf,X_train,y_train, ax, label='train')\n",
    "plot_roc_curve(rf,X_test,y_test, ax, label='test',color = 'green')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimate the maximum profit of this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T19:18:39.366178Z",
     "start_time": "2019-06-25T19:18:39.363382Z"
    }
   },
   "outputs": [],
   "source": [
    "from estimator import get_max_profit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T19:18:43.431023Z",
     "start_time": "2019-06-25T19:18:43.023460Z"
    }
   },
   "outputs": [],
   "source": [
    "get_max_profit(rf, X_test, y_test,cost_of_bads,profit_of_goods)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare Random Forest and Logisic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T19:19:10.006266Z",
     "start_time": "2019-06-25T19:19:09.428087Z"
    }
   },
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "#reload(plotting)\n",
    "from plotting import plot_roc_curve\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "plot_roc_curve(rf,X_train,y_train, ax, label='RF train',color='green',linestyle='--')\n",
    "plot_roc_curve(rf,X_test,y_test, ax, label='RF test',color = 'green')\n",
    "plot_roc_curve(lr,X_train,y_train, ax, label='LR train',color='darkred',linestyle='--')\n",
    "plot_roc_curve(lr,X_test,y_test, ax, label='LR test',color = 'darkred')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T19:46:05.039671Z",
     "start_time": "2019-06-25T19:46:05.035769Z"
    }
   },
   "outputs": [],
   "source": [
    "cost_of_bads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T19:46:35.841643Z",
     "start_time": "2019-06-25T19:46:35.838448Z"
    }
   },
   "outputs": [],
   "source": [
    "cost_of_bads, profit_of_goods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T19:51:14.156559Z",
     "start_time": "2019-06-25T19:51:13.626199Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Profit from Logistic Regression: {}\".format(get_max_profit(lr, X_test, y_test,cost_of_bads,profit_of_goods)))\n",
    "print(\"Profit from Random Forest: {}\".format(get_max_profit(rf, X_test, y_test,cost_of_bads,profit_of_goods)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If we plot now the profit dependence with the cutoff probability..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T18:17:25.125793Z",
     "start_time": "2019-06-25T18:17:24.440616Z"
    }
   },
   "outputs": [],
   "source": [
    "cost_of_bads = 10000\n",
    "profit_of_goods = 1200\n",
    "\n",
    "from plotting import plot_classifier_profit\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "plot_classifier_profit(rf,X_test,y_test, ax, cost_of_bads, profit_of_goods, label='RFtest',linestyle='--', color='darkorange')\n",
    "plot_classifier_profit(lr,X_test,y_test, ax,cost_of_bads, profit_of_goods, label='LR test',color = 'darkblue',linestyle='--')\n",
    "\n",
    "ax.set_ylim(-1e6,2e6)\n",
    "ax.set_xlim(-0,0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How does the model depend on the hyperparameters?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check first the RandomForest hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T19:22:50.836954Z",
     "start_time": "2019-06-25T19:22:50.831488Z"
    }
   },
   "outputs": [],
   "source": [
    "RandomForestClassifier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T18:11:08.152977Z",
     "start_time": "2019-06-25T18:11:08.150242Z"
    }
   },
   "outputs": [],
   "source": [
    "from plotting import plot_score_vs_hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T18:11:30.387348Z",
     "start_time": "2019-06-25T18:11:08.154509Z"
    }
   },
   "outputs": [],
   "source": [
    "rf_test = RandomForestClassifier(max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=0.0001, min_samples_split=0.5,\n",
    "            min_weight_fraction_leaf=0.0, n_estimators=700, n_jobs=1)\n",
    "param_grid={'n_estimators': range(1, 111, 10)}\n",
    "\n",
    "plot_score_vs_hyperparameter(rf_test,X_train,y_train, scoring_metric = 'roc_auc',param_grid=param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T19:23:48.765299Z",
     "start_time": "2019-06-25T19:23:17.858789Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "rf_test = RandomForestClassifier(n_estimators=70)\n",
    "param_grid={'max_depth': range(1, 18, 5)}\n",
    "\n",
    "plot_score_vs_hyperparameter(rf_test,X_train,y_train, scoring_metric = 'roc_auc',param_grid=param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Competition \n",
    "\n",
    "**Target**: Find the best model.<br>\n",
    "    \n",
    "The winner is the person who who gets the highest profits.\n",
    "\n",
    "Things you can try (score in increasing difficulty from 1 to 5)\n",
    "\n",
    "* Change hyperparameters (1)\n",
    "* Change algorithm - we did not talk about it, but if you are familiar with any other algorithm, feel free to experiment (3)\n",
    "* Try adding more features. Remember the example from the pandas notebook? (3)\n",
    "* Try a grid search/random search (see  notes below - we will cover it later) (3)\n",
    "* Try to optimize the cost function instead of the auc (tip check the function skleran.metrics.make_scorer) (5)\n",
    "* Try reducing the number of features by keeping only the most relevant ones (4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from estimator import get_max_profit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T19:47:52.881428Z",
     "start_time": "2019-06-25T19:47:51.976136Z"
    }
   },
   "outputs": [],
   "source": [
    "model = RandomForestClassifier()\n",
    "\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "plot_roc_curve(model,X_train,y_train, ax, label='train')\n",
    "plot_roc_curve(model,X_test,y_test, ax, label='test',color = 'green')\n",
    "\n",
    "print(\"Profit: {}\".format(get_max_profit(model,X_test,y_test, cost_of_bads,profit_of_goods)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do it in an automated fashion\n",
    "\n",
    "### Grid Search with cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_cv = RandomForestClassifier(max_features=None)\n",
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 10, stop = 150, num = 10)]\n",
    "\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "max_features += [x for x in range(3,30,1)]\n",
    "\n",
    "# Maximmax_featuresum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(2, 30, num = 30)]\n",
    "max_depth.append(None)\n",
    "\n",
    "min_impurity_decrease = np.linspace(0.0001, 0.3, num = 30)\n",
    "\n",
    "# Minimum number of samples required to split a node\n",
    "#min_samples_split = [int(x) for x in np.linspace(2, 10, num = 9)]\n",
    "#min_samples_split = [x for x in np.linspace(0.0001, 1, num = 30)]\n",
    "\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [x for x in np.linspace(0.0001, 0.5, num = 300)]\n",
    "# Method of selecting samples for training each t\n",
    "class_weight = [None, 'balanced']\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'min_impurity_decrease':min_impurity_decrease,\n",
    "               'bootstrap': bootstrap}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "rf_random = RandomizedSearchCV(estimator = rf_cv, scoring='roc_auc',\n",
    "                               param_distributions = random_grid, \n",
    "                               n_iter = 59, # number of itearation\n",
    "                               cv = 3, verbose=1, random_state=42, n_jobs = -1,\n",
    "                               return_train_score=True)\n",
    "# Fit the random search model\n",
    "rf_random.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_random.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's see the top 5 scores that the grid search has found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_res = pd.DataFrame(rf_random.cv_results_)\n",
    "cv_res[['mean_train_score','mean_test_score','params']].sort_values(by='mean_test_score',ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_ests = cv_res.sort_values(by='mean_test_score',ascending=False).head(3).T\n",
    "best_ests.columns=['1st','2nd','3rd']\n",
    "best_ests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Return the best estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_best = rf_random.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_best.get_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load a model that seems fine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T19:43:54.207583Z",
     "start_time": "2019-06-25T19:43:54.204593Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T19:43:54.899249Z",
     "start_time": "2019-06-25T19:43:54.660554Z"
    }
   },
   "outputs": [],
   "source": [
    "rf_best_no_overfit= joblib.load('non_overfit_rf.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T19:48:07.541118Z",
     "start_time": "2019-06-25T19:48:07.137398Z"
    }
   },
   "outputs": [],
   "source": [
    "get_max_profit(rf_best_no_overfit,X_test,y_test,cost_of_bads,profit_of_goods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T19:48:13.264442Z",
     "start_time": "2019-06-25T19:48:12.376304Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "plot_precision_recall_curve(rf_best_no_overfit,X_train,y_train, ax, label='RF train',color='green',linestyle='--')\n",
    "plot_precision_recall_curve(rf_best_no_overfit,X_test,y_test, ax, label='RF test',color = 'green')\n",
    "plot_precision_recall_curve(lr,X_train,y_train, ax, label='LR train',color='darkred',linestyle='--')\n",
    "plot_precision_recall_curve(lr,X_test,y_test, ax, label='LR test',color = 'darkred')\n",
    "ax.set_xlim(0.0001,1.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T19:49:06.048916Z",
     "start_time": "2019-06-25T19:49:06.046409Z"
    }
   },
   "outputs": [],
   "source": [
    "from plotting import plot_roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T19:49:35.476362Z",
     "start_time": "2019-06-25T19:49:34.576583Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "plot_roc_curve(rf_best_no_overfit,X_train,y_train, ax, label='RF train',color='green',linestyle='--')\n",
    "plot_roc_curve(rf_best_no_overfit,X_test,y_test, ax, label='RF test',color = 'green')\n",
    "plot_roc_curve(lr,X_train,y_train, ax, label='LR train',color='darkred',linestyle='--')\n",
    "plot_roc_curve(lr,X_test,y_test, ax, label='LR test',color = 'darkred')\n",
    "ax.set_xlim(0.0001,1.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T19:49:50.209068Z",
     "start_time": "2019-06-25T19:49:49.877836Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_confusion_matrix(rf_best_no_overfit,X_test,y_test,classes=['Good','Bad'],threshold=0.18,cmap=plt.cm.Greens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strategy Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T19:50:05.657686Z",
     "start_time": "2019-06-25T19:50:05.655125Z"
    }
   },
   "outputs": [],
   "source": [
    "from plotting import plot_strategy_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T19:50:08.475538Z",
     "start_time": "2019-06-25T19:50:06.155249Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "plot_strategy_curve(rf_best_no_overfit,X_train,y_train, ax, label='RF train',color='green',linestyle='--')\n",
    "plot_strategy_curve(rf_best_no_overfit,X_test,y_test, ax, label='RF test',color = 'green')\n",
    "plot_strategy_curve(lr,X_train,y_train, ax, label='LR train',color='darkred',linestyle='--')\n",
    "plot_strategy_curve(lr,X_test,y_test, ax, label='LR test',color = 'darkred')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### And what about the Model interpretability?\n",
    "* Can we say something about which features are important?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T19:50:26.836560Z",
     "start_time": "2019-06-25T19:50:26.511299Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15, 10))\n",
    "pd.Series(rf_best_no_overfit.feature_importances_,index = X_train.columns).sort_values(ascending=False).plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
