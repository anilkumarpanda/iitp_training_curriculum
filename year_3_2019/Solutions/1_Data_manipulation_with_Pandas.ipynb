{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T18:02:50.246261Z",
     "start_time": "2019-06-25T18:02:50.244414Z"
    }
   },
   "outputs": [],
   "source": [
    "# update to the latest version\n",
    "# ! git pull"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas is an open source library providing high-performance, easy-to-use data structures and data analysis tools for the Python programming language.<br>\n",
    "* A fast and efficient DataFrame object for data manipulation with integrated indexing\n",
    "* Tools for reading and writing data between in-memory data structures and different formats: CSV and text files, Microsoft Excel, SQL databases\n",
    "* Intelligent data alignment and integrated handling of missing data: gain automatic label-based alignment in computations and easily manipulate messy data into an orderly form\n",
    "* Flexible reshaping and pivoting of data sets;\n",
    "* Intelligent label-based slicing, fancy indexing, and subsetting of large data sets;\n",
    "* Columns can be inserted and deleted from data structures for size mutability;\n",
    "* Aggregating or transforming data with a powerful group by engine allowing split-apply-combine operations on data sets\n",
    "* High performance merging and joining of data sets\n",
    "* Time series-functionality: date range generation and frequency conversion, moving window statistics, moving window linear regressions, date shifting and lagging<br>\n",
    "<br>\n",
    "The documentation can be found on\n",
    "https://pandas.pydata.org/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T19:54:02.499940Z",
     "start_time": "2019-06-25T19:54:01.431689Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd #import pandas\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime as dt\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "pd.set_option('display.max_rows', 50)\n",
    "pd.set_option('display.max_columns', 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Series\n",
    "\n",
    "* a one-dimensional object similar to an array, list, or column in a table. \n",
    "* It will assign a labeled index to each item in the Series. \n",
    "* By default, each item will receive an index label from 0 to N, where N is the length of the Series minus one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T18:02:52.457889Z",
     "start_time": "2019-06-25T18:02:52.450409Z"
    }
   },
   "outputs": [],
   "source": [
    "serie = pd.Series([3,3.14,'Seven',None])\n",
    "serie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Index\n",
    "we can also specify the index to be something different than increasing integer numbers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T18:02:53.371007Z",
     "start_time": "2019-06-25T18:02:53.365886Z"
    }
   },
   "outputs": [],
   "source": [
    "serie2 = pd.Series([3,3.14,'Seven',None], index=['a','b','c','d'])\n",
    "serie2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or you can change it again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T18:02:54.083588Z",
     "start_time": "2019-06-25T18:02:54.080055Z"
    }
   },
   "outputs": [],
   "source": [
    "serie2.index = ['integer','float','string','null']\n",
    "serie2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a series from a dictionary\n",
    "This is very useful, because a dictionary is a python representation of a `json` format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T18:02:54.818582Z",
     "start_time": "2019-06-25T18:02:54.813157Z"
    }
   },
   "outputs": [],
   "source": [
    "d_cities_population = {'Amsterdam':821752,\n",
    "     'Istanbul':15030000,\n",
    "     'London': 8200000, \n",
    "     'Paris': 2206000, \n",
    "     'Frankfurt':  732688 , \n",
    "     'Berlin': 3700000, \n",
    "     'Hamburg': 1800000, \n",
    "     'Manchester': 541000}\n",
    "cities_population = pd.Series(d_cities_population)\n",
    "cities_population"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Index\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T18:02:55.979659Z",
     "start_time": "2019-06-25T18:02:55.975141Z"
    }
   },
   "outputs": [],
   "source": [
    "cities_population.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T18:02:56.757230Z",
     "start_time": "2019-06-25T18:02:56.753475Z"
    }
   },
   "outputs": [],
   "source": [
    "cities_population.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sorting and Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sort the cities by population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T18:02:57.793054Z",
     "start_time": "2019-06-25T18:02:57.786879Z"
    }
   },
   "outputs": [],
   "source": [
    "# if you do not specify ascending = False, it will use the default value\n",
    "# which is ascending = True\n",
    "cities_population.sort_values(ascending = False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intermezzo \n",
    "It is always useful to read the documentation of the function.<br>\n",
    "For this you can use the help function from the Jupyter Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T18:02:58.969424Z",
     "start_time": "2019-06-25T18:02:58.966223Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "help(cities_population.sort_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1\n",
    "What happens if we use <br>\n",
    "`cities_population.sort_values(inplace=True)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am interested in knowing which cities have more than 1 million citizens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T18:03:00.395868Z",
     "start_time": "2019-06-25T18:03:00.390073Z"
    }
   },
   "outputs": [],
   "source": [
    "cities_population>1000000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it returns a mask (`true` or `false`) that can be used for filtering.<br>\n",
    "Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T18:03:01.275098Z",
     "start_time": "2019-06-25T18:03:01.270413Z"
    }
   },
   "outputs": [],
   "source": [
    "cities_population[cities_population>1000000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or the inverse by using the `~` sign in fron of the mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T18:03:02.099235Z",
     "start_time": "2019-06-25T18:03:02.096324Z"
    }
   },
   "outputs": [],
   "source": [
    "mask = cities_population>1000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T18:03:02.515375Z",
     "start_time": "2019-06-25T18:03:02.509847Z"
    }
   },
   "outputs": [],
   "source": [
    "cities_population[~mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note!!!<br> \n",
    "you can save the masked filter into a variable (in the example `mask`) or use it explicity (like done above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a dataframe from two series.\n",
    "For this purpose, we need a new series with similar indexes<br>\n",
    "Let's create one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T18:03:03.877987Z",
     "start_time": "2019-06-25T18:03:03.872763Z"
    }
   },
   "outputs": [],
   "source": [
    "d_cities_country = {'Amsterdam':'Netherlands',\n",
    "     'Istanbul':'Turkey',\n",
    "     'London': 'UK', \n",
    "     'Paris': 'France', \n",
    "     'Frankfurt': 'Germany', \n",
    "     'Berlin': 'Germany', \n",
    "     'Hamburg': 'Germany', \n",
    "     'Lyon':'France',\n",
    "     'Manchester': 'UK'}\n",
    "cities_country = pd.Series(d_cities_country)\n",
    "cities_country"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Counting values\n",
    "How many cities do I have per country in by dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T18:03:05.045061Z",
     "start_time": "2019-06-25T18:03:05.039712Z"
    }
   },
   "outputs": [],
   "source": [
    "cities_country.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note the output of value_counts is a Serie, where now the index is the unique value, and the value is the number of times it appears\n",
    "\n",
    "What would happen if we apply `value_counts` twice, i.e.<br>\n",
    "\n",
    "`cities_country.value_counts().value_counts()`?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Dataframes\n",
    "\n",
    "* Two-dimensional size-mutable, potentially heterogeneous tabular data structure with labeled axes (rows and columns). \n",
    "* Arithmetic operations align on both row and column labels. \n",
    "* Can be thought of as a dict-like container for Series objects. \n",
    "* The primary pandas data structure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pandas concat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the `help(pd.concat)` to see what this is doing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T18:03:07.810915Z",
     "start_time": "2019-06-25T18:03:07.806044Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.concat([cities_country, cities_population])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Not really what we wanted, right?\n",
    "* Pandas uses a `'two-dimensional'` representation of the data (table), with  rows and columns.<br>\n",
    "* When applying an operation, we need to specify the direction (i.e. along the rows of the columns)<br>\n",
    "* This is defined by the `axis` parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T18:03:08.774495Z",
     "start_time": "2019-06-25T18:03:08.768458Z"
    }
   },
   "outputs": [],
   "source": [
    "### concat along the 2nd axix (python starts indexing from 0)\n",
    "### We will save the output into a new object, called cities\n",
    "cities=pd.concat([cities_country, cities_population], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T18:03:09.222328Z",
     "start_time": "2019-06-25T18:03:09.209914Z"
    }
   },
   "outputs": [],
   "source": [
    "cities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This is a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T18:03:10.007162Z",
     "start_time": "2019-06-25T18:03:10.003679Z"
    }
   },
   "outputs": [],
   "source": [
    "type(cities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How about we give a nice name to the columns?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T18:03:11.054555Z",
     "start_time": "2019-06-25T18:03:11.045669Z"
    }
   },
   "outputs": [],
   "source": [
    "cities.columns=['Country','Population']\n",
    "cities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing the column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T18:03:12.076532Z",
     "start_time": "2019-06-25T18:03:12.071788Z"
    }
   },
   "outputs": [],
   "source": [
    "cities['Country']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2:\n",
    "What is the difference between :\n",
    "* `cities['Country']`\n",
    "* `cities[['Country']]`\n",
    "* `cities.Country`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filters, sorting\n",
    "It works the same way as in Series<br>\n",
    "Let's filter out the missing value of `Lyon`\n",
    "the function isnull() will tell if the value is null or not"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cities.isnull()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and we can use this mapping for filtering values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T18:03:13.966936Z",
     "start_time": "2019-06-25T18:03:13.958415Z"
    }
   },
   "outputs": [],
   "source": [
    "cities[~cities.Population.isnull()] #remember, ~ is negation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Operations on the DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a function that will categorise the cities in EU and non EU ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T18:03:15.106025Z",
     "start_time": "2019-06-25T18:03:15.102658Z"
    }
   },
   "outputs": [],
   "source": [
    "def is_EU(x):\n",
    "    return x in ['Netherlands','Germany','UK','France']\n",
    "\n",
    "def is_EU_after2019(x):\n",
    "    '''\n",
    "    remove the UK after Brexit\n",
    "    '''\n",
    "    return x in ['Netherlands','Germany','France']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T18:03:15.751507Z",
     "start_time": "2019-06-25T18:03:15.747114Z"
    }
   },
   "outputs": [],
   "source": [
    "cities['Country'].apply(is_EU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T18:03:16.140838Z",
     "start_time": "2019-06-25T18:03:16.136381Z"
    }
   },
   "outputs": [],
   "source": [
    "cities['Country'].apply(is_EU_after2019)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### But We would like something nicer, like a column saying if it is EU or non EU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T18:03:17.079027Z",
     "start_time": "2019-06-25T18:03:17.071574Z"
    }
   },
   "outputs": [],
   "source": [
    "cities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying a function return a series. We can add it as a new column to the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T18:03:18.006130Z",
     "start_time": "2019-06-25T18:03:18.003208Z"
    }
   },
   "outputs": [],
   "source": [
    "cities['isEU']=cities['Country'].apply(is_EU_after2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T18:03:18.281540Z",
     "start_time": "2019-06-25T18:03:18.271900Z"
    }
   },
   "outputs": [],
   "source": [
    "cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T18:03:18.528221Z",
     "start_time": "2019-06-25T18:03:18.524186Z"
    }
   },
   "outputs": [],
   "source": [
    "### Lets now convert it into Strings\n",
    "cities['European_Union']=cities.isEU.apply(lambda x: 'EU' if x else 'no EU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T18:03:18.847922Z",
     "start_time": "2019-06-25T18:03:18.837864Z"
    }
   },
   "outputs": [],
   "source": [
    "cities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The drop function\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T18:03:19.556697Z",
     "start_time": "2019-06-25T18:03:19.548499Z"
    }
   },
   "outputs": [],
   "source": [
    "cities.drop('isEU', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The same can be achieved by selecting the columns we want to keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T18:03:20.177132Z",
     "start_time": "2019-06-25T18:03:20.169091Z"
    }
   },
   "outputs": [],
   "source": [
    "cities[['Country','Population','European_Union']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T18:03:20.510740Z",
     "start_time": "2019-06-25T18:03:20.507444Z"
    }
   },
   "outputs": [],
   "source": [
    "#REMOVE IN PLACE\n",
    "cities.drop('isEU',inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T18:03:20.815363Z",
     "start_time": "2019-06-25T18:03:20.805419Z"
    }
   },
   "outputs": [],
   "source": [
    "cities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing Values\n",
    "\n",
    "Missing values can be replaced by the fillna function.<br>\n",
    "Let's see the help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T18:03:21.578137Z",
     "start_time": "2019-06-25T18:03:21.575135Z"
    }
   },
   "outputs": [],
   "source": [
    "help(cities.fillna)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our use case, we want to replace the Population of Lyon with the value we know from Wikipedia, cca half a milion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T18:03:21.777498Z",
     "start_time": "2019-06-25T18:03:21.765001Z"
    }
   },
   "outputs": [],
   "source": [
    "cities.fillna(value=500000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### It might be a bit safer to specify directly the column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T18:03:21.918254Z",
     "start_time": "2019-06-25T18:03:21.915760Z"
    }
   },
   "outputs": [],
   "source": [
    "cities.Population.fillna(value=500000,inplace=True) # note the inplace=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T18:03:21.999837Z",
     "start_time": "2019-06-25T18:03:21.991354Z"
    }
   },
   "outputs": [],
   "source": [
    "cities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3:\n",
    "The population is a float. Convert it to integers"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "*** your solution here ***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group-By and Aggregations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T18:03:22.335832Z",
     "start_time": "2019-06-25T18:03:22.333569Z"
    }
   },
   "outputs": [],
   "source": [
    "grouped_cities = cities.groupby('Country')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is it a Dataframe? Not really"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T18:03:22.503324Z",
     "start_time": "2019-06-25T18:03:22.500528Z"
    }
   },
   "outputs": [],
   "source": [
    "type(grouped_cities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loop over the different groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T18:03:22.683944Z",
     "start_time": "2019-06-25T18:03:22.669666Z"
    }
   },
   "outputs": [],
   "source": [
    "for group, df in grouped_cities:\n",
    "    print(df)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply functions\n",
    "\n",
    "Sum the population of the country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T18:03:22.856542Z",
     "start_time": "2019-06-25T18:03:22.851049Z"
    }
   },
   "outputs": [],
   "source": [
    "grouped_cities['Population'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple aggregations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T18:03:23.013178Z",
     "start_time": "2019-06-25T18:03:23.002112Z"
    }
   },
   "outputs": [],
   "source": [
    "countries = grouped_cities['Population'].aggregate({'Total population':'sum', 'Average_popoulation':'mean'})\n",
    "countries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The group-by key (Country in our case) is by default is now an index.\n",
    "\n",
    "But it is probably more useful to have it as a columt in a new DataFrame.<br>\n",
    "If you check the groupby documentation, we can see that there is the parameters `as_index`, which is True by default.<br>\n",
    "Setting it to False does the trick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T18:03:23.185903Z",
     "start_time": "2019-06-25T18:03:23.175025Z"
    }
   },
   "outputs": [],
   "source": [
    "countries = cities.groupby('Country', as_index=False)['Population'].aggregate(\n",
    "    {'Total_population':'sum', 'Average_popoulation':'mean'}\n",
    ")\n",
    "countries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joining DataFrames\n",
    "https://pandas.pydata.org/pandas-docs/stable/merging.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T18:03:23.338711Z",
     "start_time": "2019-06-25T18:03:23.335741Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "help(pd.merge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T18:03:23.434932Z",
     "start_time": "2019-06-25T18:03:23.424446Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.merge(left=cities,\n",
    "        right = countries,\n",
    "        on='Country')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Where are the names of the cities?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T18:03:23.592274Z",
     "start_time": "2019-06-25T18:03:23.589010Z"
    }
   },
   "outputs": [],
   "source": [
    "cities['City'] = cities.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T18:03:23.671934Z",
     "start_time": "2019-06-25T18:03:23.668910Z"
    }
   },
   "outputs": [],
   "source": [
    "cities.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we can rejoin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T18:03:23.865449Z",
     "start_time": "2019-06-25T18:03:23.854014Z"
    }
   },
   "outputs": [],
   "source": [
    "extended_cities = pd.merge(left=cities,\n",
    "        right = countries,\n",
    "        on='Country')\n",
    "extended_cities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now we have more information. We could use it to create more features/variables\n",
    "\n",
    "For instance, I want to know which fraction of the country population is from a given city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T18:03:24.030001Z",
     "start_time": "2019-06-25T18:03:24.015026Z"
    }
   },
   "outputs": [],
   "source": [
    "extended_cities['Populatiion_fraction']=extended_cities['Population']/extended_cities['Total_population']\n",
    "extended_cities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Reading data from files\n",
    "\n",
    "So far we have seen academic examples with random generated data.<br>\n",
    "Let's actually see how we can import data from files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T18:03:24.203422Z",
     "start_time": "2019-06-25T18:03:24.199629Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "help(pd.read_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T19:54:34.322606Z",
     "start_time": "2019-06-25T19:54:34.221178Z"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/UCI_Credit_Card.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset has been downloaded from kaggle\n",
    "\n",
    "https://www.kaggle.com/uciml/default-of-credit-card-clients-dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's get some general information about the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many rows and columns?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T18:03:24.602036Z",
     "start_time": "2019-06-25T18:03:24.599245Z"
    }
   },
   "outputs": [],
   "source": [
    "data.shape\n",
    "# 30000 rows and 25 columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which columns do we have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T18:03:24.774447Z",
     "start_time": "2019-06-25T18:03:24.770894Z"
    }
   },
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can we say something more about it? For instance, of which type is the data contained in the columns?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T18:03:24.937391Z",
     "start_time": "2019-06-25T18:03:24.933083Z"
    }
   },
   "outputs": [],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Important:\n",
    "\n",
    "Before doing any data science project, it is important to understand the inputs?\n",
    "On the kaggle website you can find the information about the dataset, which is reported below\n",
    "\n",
    "Content\n",
    "\n",
    "There are 25 variables:\n",
    "\n",
    "* ID: ID of each client\n",
    "* LIMIT_BAL: Amount of given credit in NT dollars (includes individual and family/supplementary credit\n",
    "* SEX: Gender (1=male, 2=female)\n",
    "* EDUCATION: (1=graduate school, 2=university, 3=high school, 4=others, 5=unknown, 6=unknown)\n",
    "* MARRIAGE: Marital status (1=married, 2=single, 3=others)\n",
    "* AGE: Age in years\n",
    "* PAY_0: Repayment status in September, 2005 (-1=pay duly, 1=payment delay for one month, 2=payment delay for two months, ... 8=payment delay for eight months, 9=payment delay for nine months and above)\n",
    "* PAY_2: Repayment status in August, 2005 (scale same as above)\n",
    "* PAY_3: Repayment status in July, 2005 (scale same as above)\n",
    "* PAY_4: Repayment status in June, 2005 (scale same as above)\n",
    "* PAY_5: Repayment status in May, 2005 (scale same as above)\n",
    "* PAY_6: Repayment status in April, 2005 (scale same as above)\n",
    "* BILL_AMT1: Amount of bill statement in September, 2005 (NT dollar)\n",
    "* BILL_AMT2: Amount of bill statement in August, 2005 (NT dollar)\n",
    "* BILL_AMT3: Amount of bill statement in July, 2005 (NT dollar)\n",
    "* BILL_AMT4: Amount of bill statement in June, 2005 (NT dollar)\n",
    "* BILL_AMT5: Amount of bill statement in May, 2005 (NT dollar)\n",
    "* BILL_AMT6: Amount of bill statement in April, 2005 (NT dollar)\n",
    "* PAY_AMT1: Amount of previous payment in September, 2005 (NT dollar)\n",
    "* PAY_AMT2: Amount of previous payment in August, 2005 (NT dollar)\n",
    "* PAY_AMT3: Amount of previous payment in July, 2005 (NT dollar)\n",
    "* PAY_AMT4: Amount of previous payment in June, 2005 (NT dollar)\n",
    "* PAY_AMT5: Amount of previous payment in May, 2005 (NT dollar)\n",
    "* PAY_AMT6: Amount of previous payment in April, 2005 (NT dollar)\n",
    "* default.payment.next.month: Default payment (1=yes, 0=no)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hmmm... Why in the Pay column we have a 0 for september, and in the rest is a 1?\n",
    "Let's rename it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise: \n",
    "Convert the name of the column from PAY_0 to PAY_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T18:03:25.266493Z",
     "start_time": "2019-06-25T18:03:25.263635Z"
    }
   },
   "outputs": [],
   "source": [
    "*** your solution here ***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking only the first 10 rows to inspect the values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T18:03:25.459372Z",
     "start_time": "2019-06-25T18:03:25.438614Z"
    }
   },
   "outputs": [],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or the last 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T18:03:25.620189Z",
     "start_time": "2019-06-25T18:03:25.599399Z"
    }
   },
   "outputs": [],
   "source": [
    "data.tail(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## See some statistics about my dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T18:03:25.865372Z",
     "start_time": "2019-06-25T18:03:25.772296Z"
    }
   },
   "outputs": [],
   "source": [
    "data.describe() # shows the basic stats about the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing values\n",
    "Before starting processing the data, we need to check if there are any missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T18:03:25.959042Z",
     "start_time": "2019-06-25T18:03:25.940107Z"
    }
   },
   "outputs": [],
   "source": [
    "data.isnull().head() # returns True if any of the values in the column is missing, otherwise it is a false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T18:03:26.051786Z",
     "start_time": "2019-06-25T18:03:26.038958Z"
    }
   },
   "outputs": [],
   "source": [
    "# any() applieas the any() function on all the columns. \n",
    "# If there is a single value that is True, it will return True\n",
    "data.isnull().any() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our case we are lucky (all the values are False, we do not have any missing values). <br>\n",
    "However, in case of missing values, one needs to think of a strategy to deal with them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intermezzo: list comprehension in python and applications to a Dataframe\n",
    "List comprehension is an elegant way to define and create lists in Python. <br>\n",
    "\n",
    "Example: I want to create a list of the numbers from 1 to 10 that are divisible by 3\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T18:03:26.270717Z",
     "start_time": "2019-06-25T18:03:26.267543Z"
    }
   },
   "outputs": [],
   "source": [
    "# Returns all the numbers from 0 to 9 included\n",
    "[x for x in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T18:03:26.367260Z",
     "start_time": "2019-06-25T18:03:26.362855Z"
    }
   },
   "outputs": [],
   "source": [
    "# Returns all the numbers from 0 to 9 included where the remainder of the division by 3 is 0 \n",
    "# (hence numbers divisible by 3)\n",
    "[x for x in range(10) if x%3==0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Back to the DataFrames\n",
    "Example: `data.columns` will return an iterable that will represent the columns of the DataSet. <br>\n",
    "\n",
    "Let's say we are interested in showing the statistics of the columns related to the BILL of the month.<br>\n",
    "All of this columns start with `BILL_*`, and we can use this knowledge to select them in one line of code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T18:03:26.548360Z",
     "start_time": "2019-06-25T18:03:26.544113Z"
    }
   },
   "outputs": [],
   "source": [
    "# List comprehension\n",
    "# Return all the columns of the dataframe data where the first 4 characthers equal 'BILL'\n",
    "[col for col in data.columns if col[:4]=='BILL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T18:03:26.616584Z",
     "start_time": "2019-06-25T18:03:26.606662Z"
    }
   },
   "outputs": [],
   "source": [
    "# And using this to slice the columns\n",
    "data[[col for col in data.columns if col[:4]=='BILL']].head() # remember, head() shows only the first 5 rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another example: <br>\n",
    "    \n",
    "Let's find the 'categorial' variables: let's assume that categorical variables are those with less than 10 unique values.<br>\n",
    "`data['PAY_1'].unique()` will return all the unique values of PAY_1 category "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T18:03:26.848178Z",
     "start_time": "2019-06-25T18:03:26.775497Z"
    }
   },
   "outputs": [],
   "source": [
    "print('array:',data['PAY_1'].unique()) # returns the array\n",
    "print('length:',data['PAY_1'].unique().shape[0]) # returns the length of the array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using list comprehension, we can find the 'categorical' columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T18:03:26.970325Z",
     "start_time": "2019-06-25T18:03:26.950928Z"
    }
   },
   "outputs": [],
   "source": [
    "[col for col in data.columns if data[col].unique().shape[0]<10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical variables\n",
    "\n",
    "The trick that we have shown above works in most of the cases, however, one needs to be careful with categorical variables.<br>\n",
    "By taking the definition from wikipedia:<br>\n",
    "* In statistics, a categorical variable is a variable that can take on one of a limited, and usually fixed, number of possible values, assigning each individual or other unit of observation to a particular group or nominal category on the basis of some qualitative property.<br>\n",
    "\n",
    "Categorical variables if represented with numbers (like in our example) could induce our machine learning model in trouble, as the model will interpret them as ordered values.<br>\n",
    "Take the categorical variables in  our dataset: \n",
    "* SEX: Gender (1=male, 2=female)\n",
    "* EDUCATION: (1=graduate school, 2=university, 3=high school, 4=others, 5=unknown, 6=unknown)\n",
    "* MARRIAGE: Marital status (1=married, 2=single, 3=others)\n",
    "\n",
    "One can see that `FEMALE`>`MALE` (2>1), but this does not make any sense from the mathematical point of view.\n",
    "Let's do the exercise, and then we will see how to deal with it\n",
    "\n",
    "### Categorical variables: (one-hot) encodings\n",
    "We would like to represent our categorical variables in a way that our model can process them without wrongly assuming an ordered dependence.<br>\n",
    "one-hot is a group of bits among which the legal combinations of values are only those with a single high (1) bit and all the others low (0)\n",
    "Let's see an example that will make it more clear:<br>\n",
    "in `pandas` you can create one-hot encodings by using pd.get_dummies()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T18:03:27.115533Z",
     "start_time": "2019-06-25T18:03:27.109520Z"
    }
   },
   "outputs": [],
   "source": [
    "data['SEX'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T18:03:27.201875Z",
     "start_time": "2019-06-25T18:03:27.193732Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.get_dummies(data['SEX']).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T18:03:27.312241Z",
     "start_time": "2019-06-25T18:03:27.297452Z"
    }
   },
   "outputs": [],
   "source": [
    "ohe_data = pd.get_dummies(data,columns = ['SEX','MARRIAGE','EDUCATION'])\n",
    "ohe_data.shape, data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note:\n",
    "* we saved the one-hot encoded DataFrame into a new variable (`ohe_data`)\n",
    "* if we look at the shape, we added 8 more columns. This what happens with OHE - dimensions can explode quickly!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation between variables\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T18:03:27.644233Z",
     "start_time": "2019-06-25T18:03:27.536113Z"
    }
   },
   "outputs": [],
   "source": [
    "ohe_data.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T18:03:28.625820Z",
     "start_time": "2019-06-25T18:03:27.646072Z"
    }
   },
   "outputs": [],
   "source": [
    "from plotting import plot_dataframe_correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T18:03:31.378097Z",
     "start_time": "2019-06-25T18:03:28.627519Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_dataframe_correlations(ohe_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's check the correlations with our target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T18:03:31.431422Z",
     "start_time": "2019-06-25T18:03:31.380518Z"
    }
   },
   "outputs": [],
   "source": [
    "ohe_data.corr()['default.payment.next.month'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering - an example\n",
    "\n",
    "In view of builiding a model, we would like to enrich the information that we have, by creating features.<br>\n",
    "This could allow our model to perform better.<br>\n",
    "<br>\n",
    "Feature engineering is driven by the creativity of the Data Scientist, common sense, and business logic.<br>\n",
    "In our problem, we would like to be able to predict defaults (i.e. the value of `default.payment.next.month`). <br>\n",
    "We see that we have a lot of information available per a single client: by common sense, we can immagine that the comparison of the BILL amount to the total limit on the credit card might be a good indicator of a probable default.<br>\n",
    "We can create a feature that will be representative of this, by taking the ratio of the BILL_AMT to the LIMIT_BAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T18:03:31.438783Z",
     "start_time": "2019-06-25T18:03:31.433110Z"
    }
   },
   "outputs": [],
   "source": [
    "ohe_data['BILL_AMT1']/ohe_data['LIMIT_BAL']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could also do it for all the bills, in a loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T18:03:31.444000Z",
     "start_time": "2019-06-25T18:03:31.440252Z"
    }
   },
   "outputs": [],
   "source": [
    "# as before\n",
    "bill_columns = [col for col in ohe_data.columns if col[:4]=='BILL']\n",
    "bill_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also want to create new names of the columns. We can use the string.format from python.<br>\n",
    "See this example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T18:03:31.448500Z",
     "start_time": "2019-06-25T18:03:31.445311Z"
    }
   },
   "outputs": [],
   "source": [
    "for col in bill_columns:\n",
    "    print('ratio_{}_to_LIMIT'.format(col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T18:03:31.458153Z",
     "start_time": "2019-06-25T18:03:31.450678Z"
    }
   },
   "outputs": [],
   "source": [
    "for col in bill_columns:\n",
    "    \n",
    "    # define the new column name\n",
    "    new_column_name = 'ratio_{}_to_LIMIT'.format(col)\n",
    "    \n",
    "    # perform the ratio operation, and assign it to the new column\n",
    "    ohe_data[new_column_name]=ohe_data[col]/ohe_data['LIMIT_BAL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T18:03:31.464080Z",
     "start_time": "2019-06-25T18:03:31.460713Z"
    }
   },
   "outputs": [],
   "source": [
    "# as expected, we added 6 new columns (we had 33 before)\n",
    "ohe_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions on rows\n",
    "\n",
    "Above we have seen how to apply a functoin on a column value.<br>\n",
    "But what about applying a function on rows. <br>\n",
    "\n",
    "For instance, if you want to compute the average bill "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T18:03:31.470374Z",
     "start_time": "2019-06-25T18:03:31.466375Z"
    }
   },
   "outputs": [],
   "source": [
    "def find_mean(df, columns):\n",
    "    \n",
    "    sum_ = 0\n",
    "    for column in columns:\n",
    "        sum_ += df[column]\n",
    "        \n",
    "    return sum_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T18:03:32.720505Z",
     "start_time": "2019-06-25T18:03:31.472445Z"
    }
   },
   "outputs": [],
   "source": [
    "data['average_bill'] = data.apply(lambda x: find_mean(x,bill_columns), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T15:05:33.951610Z",
     "start_time": "2019-06-25T15:05:33.948101Z"
    }
   },
   "source": [
    "# Exercise (20 minutes)\n",
    "\n",
    "Earlier we looked into fitting 6 points with a linear regression.<br>\n",
    "Now we want to use it to our advantage, by building a feature that tells us something about the change in trend, for instance:\n",
    "* is the bill amount increasing or decreasing in the last 6 months?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T18:03:57.464645Z",
     "start_time": "2019-06-25T18:03:57.459853Z"
    }
   },
   "outputs": [],
   "source": [
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T18:03:57.890523Z",
     "start_time": "2019-06-25T18:03:57.887331Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_trend(df,columns):\n",
    "    coordinates = [(-ix,df[column]) for ix, column in enumerate(columns)]\n",
    "    \n",
    "    return utils.compute_slope(*coordinates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T18:04:10.853217Z",
     "start_time": "2019-06-25T18:04:09.491251Z"
    }
   },
   "outputs": [],
   "source": [
    "data['bill_trend'] = data.apply(lambda x: compute_trend(x,bill_columns), axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T18:04:16.098653Z",
     "start_time": "2019-06-25T18:04:16.077399Z"
    }
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exporting the dataframe to a file \n",
    "\n",
    "The dataframe can be exported to different format, using different functions, with the most common being:<br>\n",
    "* `to_csv()`: save it to a csv (comma separated values) file\n",
    "* `to_pickle()`: save it to pickle. Pickle is a compression of python objects. It is useful to save any form of object (like your data, but also models, arrays etc) that can be read in another python session\n",
    "* `to_json()`: save it to json\n",
    "* `to_excel()`: well, we work in a bank, sometimes we need excel as well :(\n",
    "\n",
    "Read the documentation of each function, to be sure you do not miss some important details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T18:04:26.042866Z",
     "start_time": "2019-06-25T18:04:25.146237Z"
    }
   },
   "outputs": [],
   "source": [
    "ohe_data.to_csv('data/processed_data_by_trainees.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T18:04:27.265846Z",
     "start_time": "2019-06-25T18:04:27.133611Z"
    }
   },
   "outputs": [],
   "source": [
    "# lets see the content of the folder data (! executes a unix command, but this goes beyond the scope of this training)\n",
    "! ls -lh data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting with pandas\n",
    "Pandas has some integrated functions to do quick plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T18:04:36.837516Z",
     "start_time": "2019-06-25T18:04:36.688550Z"
    }
   },
   "outputs": [],
   "source": [
    "data['AGE'].hist(color='blue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scatter plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T18:04:38.325186Z",
     "start_time": "2019-06-25T18:04:37.904745Z"
    }
   },
   "outputs": [],
   "source": [
    "data.plot(kind='scatter', x='BILL_AMT1', y='PAY_AMT1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot histograms by different groupby keys\n",
    "Example, how doe the age distribution for male and female look like?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T18:04:39.486877Z",
     "start_time": "2019-06-25T18:04:39.149991Z"
    }
   },
   "outputs": [],
   "source": [
    "data[['AGE','SEX']].hist(by='SEX', figsize=(12, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T18:04:39.841959Z",
     "start_time": "2019-06-25T18:04:39.590546Z"
    }
   },
   "outputs": [],
   "source": [
    "data[[col for col in data.columns if 'PAY_AMT' in col]].plot.box(figsize=(20, 8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time series\n",
    "\n",
    "`Definition`: a time series is a series of data points indexed (or listed or graphed) in time order. Most commonly, a time series is a sequence taken at successive equally spaced points in time. Thus it is a sequence of discrete-time data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In pandas you can plot time series as well.\n",
    "By selecting a column and then calling plot, it will plot the values ordered by the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T18:04:42.771851Z",
     "start_time": "2019-06-25T18:04:42.615512Z"
    }
   },
   "outputs": [],
   "source": [
    "# This is not really a time series (as each index represent a different client, so they are not a dependent sequence), \n",
    "# but we show it here for the sake of teaching the pandas API \n",
    "data['PAY_AMT1'].plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
